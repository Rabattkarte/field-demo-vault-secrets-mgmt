slug: vault-demo-app
id: gc5ak3quhakx
type: track
title: HashiCups Store (Vault Challenge Scenario)
teaser: Help get HashiCups, Inc. into regulatory compliance.
description: HashiCups, Inc. has been caught with bad secrets management practices
  by independent auditors. Learn how to migrate old application secrets and get HashiCups,
  Inc. compliant.
icon: https://storage.googleapis.com/instruqt-frontend/assets/hashicorp/tracks/vault.png
tags:
- vault
- aws
- demo-app
owner: hashicorp
developers:
- neil@hashicorp.com
- lance@hashicorp.com
private: false
published: true
challenges:
- slug: time-to-change
  id: xegkefzbeka5
  type: challenge
  title: Time to Change
  teaser: Busted! Secrets at HashiCups, Inc. are not centralized or governed. It's
    time to change.
  assignment: |-
    The [root token](https://www.vaultproject.io/docs/concepts/tokens/) for this Vault
    installation is simply "root". Using the root token, you'll have full access to Vault
    to begin this challenge.

    You can log in using `vault login root` or by typing `root` into the token auth method
    field in the UI.

    ---

    Though your team has already deployed all of the components of the HashiCups
    Store into Kubernetes already, when you open up the HashiCups Store tab,
    you see the app is showing "`Error :(`".

    The secrets used to connect each component must not have been migrated
    over to Vault correctly. You know your team member has already migrated the secret
    into Vault, but you don't know at what path it is stored.

    Everything in Vault is path based, so the first thing you will need to do
    is find out at what path the `kv` secrets engine is mounted.

    ```
    vault secrets list
    ```

    Notice that the `kv` secrets engine is mounted at the path `kv/`. Next, you
    need to list the keys of that `kv` mount until you find the Customer Profile
    Postgres database credentials.

    ```
    vault kv list kv
    ```

    Note that there is a key inside the `kv` mount already (`db`). Continue digging
    using `vault kv list` to get familiar with path based secrets.

    ```
    vault kv list kv/db
    vault kv list kv/db/postgres
    ```

    You can also open up the Vault UI tab, type "root" into the Token auth method, and
    log in to visually browse the `kv` mount.

    Since you know the `products-api` needs to talk to the `postgres` service,
    you should start there. You can read a secret with the `read` command.

    ```
    vault read kv/db/postgres/product-db-creds
    ```

    Something about the password doesn't look right...

    Now that you have an idea of how path based secrets are laid out in Vault's `kv` secrets
    engine, let's start fixing the HashiCups store.
  notes:
  - type: text
    contents: |-
      You are a DevOps engineer at HashiCups.

      HashiCups has recently been audited by regulators and as a result of the
      audit, it was exposed that the HashiCups Store app has poor secrets
      management posture. For example. the auditors found secrets for the app
      in plain text in git repos, shared mounts, and spreadsheets.

      To satisfy the regulators and auditors, HashiCups has decided to adopt
      Vault as a centralized secrets management service. Your team has been
      tasked with migrating from your legacy secret storage to the new, Vault
      secrets management solution.
  - type: text
    contents: |-
      Vault is a tool for securely accessing secrets. A secret is anything that
      you want to tightly control access to, such as API keys, passwords, or
      certificates.

      Vault provides a unified interface to any secret, while providing tight
      access control and recording a detailed audit log.
  - type: text
    contents: |-
      Vault has two important concepts to be aware of for this track:

      - Auth Methods
        - Are the components in Vault that perform authentication and
        are responsible for assigning identity and a set of policies to a user.
      - Secrets Engines
        - Are components which store, generate, or encrypt data.
        - Are incredibly flexible, so it is easiest to think about them in terms
        of their function.
        - Are provided some set of data, they take some action on that data,
        and they return a result.

      You can visually see how these interact on the next slide.
  - type: text
    contents: '![Vault Triangle](https://github.com/hashicorp/field-demo-vault-secrets-mgmt/raw/master/images/vault-triangle.png)'
  - type: text
    contents: |-
      The HashiCups Store itself consists of several different components, all
      running within Kubernetes. Many of these components require a secret to
      interact with another component.
  - type: text
    contents: |-
      The first components we'll take a look at are:

        - [`frontend`](https://github.com/hashicorp-demoapp/frontend)
          - A front end web service for displaying HashiCups products.
        - [`product-api`](https://github.com/hashicorp-demoapp/product-api-go)
          - A REST API service abstracting the `products` database in `postgres`
          - _Requires credentials to connect to `postgres`_
        - `postgres`
          - A Postgres database that contains the HashiCups products

      On the next slide, you can see how all the components interact. Don't worry
      about remembering it all now, we'll address them each in this track.
  - type: text
    contents: '![HashiCups Reference Architecture Diagram](https://github.com/hashicorp/field-demo-vault-secrets-mgmt/raw/master/images/infa.png)'
  - type: text
    contents: |-
      Your team has already deployed all of the components of the HashiCups
      Store into Kubernetes, and one of your team members has already configured
      the [`kubernetes` Auth Method](https://www.vaultproject.io/docs/auth/kubernetes/)
      in Vault.

      The `kubernetes` auth method can be used to authenticate with Vault using a
      Kubernetes Service Account Token. This method of authentication makes it easy
      to introduce a Vault token into a Kubernetes Pod.

      Because this has already been configured, you don't have to worry about how
      the Kubernetes pods in the next steps are authenticating to Vault.
  tabs:
  - title: Terminal
    type: terminal
    hostname: workstation
  - title: Vault UI
    type: service
    hostname: workstation
    path: /ui/
    port: 30082
  - title: Consul UI
    type: service
    hostname: workstation
    path: /ui/
    port: 30085
  - title: K8s UI
    type: service
    hostname: workstation
    port: 30443
  - title: HashiCups Store
    type: service
    hostname: workstation
    path: /
    port: 30090
  difficulty: basic
  timelimit: 120
- slug: migrating-static-database-secrets
  id: 3wunlrlkq2nz
  type: challenge
  title: Migrating Static Database Secrets
  teaser: Migrate your first secret from a shared mount to Vault.
  assignment: |-
    When the HashiCups Store was audited, the auditors found, among other things,
    that the Postgres Products database credentials were clearly visible to all
    internal team members on a shared drive, at `/share/postgres-product-creds.txt`.

    You should compare what is in the shared file and what you just read out of Vault.

    ```
    cat /share/postgres-product-creds.txt
    ```

    Take the values from that file, and write them to correct path in Vault. It might
    help to set them as env vars first.

    ```
    export PG_USER="postgres"
    export PG_PASS="password"
    ```

    Then write the values to Vault.

    ```
    vault kv put kv/db/postgres/product-db-creds \
      username=$PG_USER \
      password=$PG_PASS
    ```

    Once you have updated the static credentials, you should redeploy the app so
    that it pulls the latest credentials. Since we are running all of our components
    in Kubernetes, we can do that with
    [`kubectl`](https://kubernetes.io/docs/reference/kubectl/overview/).

    *TODO: VAULT AGENT DESCRIPTION*

    You can see all of the deployments in your Kubernetes cluster.

    ```
    kubectl get deploy
    ```

    You should restart the `products-api-deployment`, you can do that with a single
    command.

    ```
    kubectl rollout restart deployment products-api-deployment
    ```

    Once the deployment has been restarted, open up the HashiCups Store tab again
    and refresh the page. You should be able to see one of the HashiCups products now.

    Now that you've migrated the credentials from the old shared file into Vault,
    remove it.

    ```
    rm /share/postgres-product-creds.txt
    ```

    Now that the secret is protected by Vault, you've taken one step in the right
    direction towards good secrets management hygiene.
  notes:
  - type: text
    contents: |-
      The first secret that needs your attention is the credential set for the
      Products database. These credentials are used by the HashiCups Store's
      Product API service to pull in all of the products available to consumers.

      The credentials are currently stored in a text file on a shared mount.
      All of your team members at HashiCups have access to this shared mount,
      and whenever you need to deploy the app, a DBA SSHes into a box, references
      the file in the shared mount, and updates the app.
  - type: text
    contents: |-
      This has caused a major issue for the auditors. You need to make sure that
      the credentials have been migrated correctly from the filesystem to Vault.
      Once you've done that, you need to make sure that only the identities that
      need access can access the secret, and then you should make the secret
      dynamic.

      More on that later.

      Your first task is to make sure those shared database credentials are correctly
      input into Vault.
  tabs:
  - title: Terminal
    type: terminal
    hostname: workstation
  - title: Vault UI
    type: service
    hostname: workstation
    path: /ui/
    port: 30082
  - title: Consul UI
    type: service
    hostname: workstation
    path: /ui/
    port: 30085
  - title: K8s UI
    type: service
    hostname: workstation
    port: 30443
  - title: HashiCups Store
    type: service
    hostname: workstation
    path: /
    port: 30090
  difficulty: basic
  timelimit: 300
- slug: restricting-access-to-secrets-using-acls
  id: zmkod8j9pbw1
  type: challenge
  title: Restricting Access to Secrets Using ACLs
  teaser: Now that you've fixed your first Vault secret, make sure only the right
    identities can read it.
  assignment: |-
    There are two primary roles that need to access the Customer Profile database: DBAs
    (`dba-operators`) and the Products API (`products-api`) itself. The DBAs should be able to
    perform all operations on the `kv/database/` path. The web service should only be able
    to read secrets at that path.

    You have been provided with pre-written ACL policies - one for the DBA operator
    and one for the HashiCups Products API. Take a look at them to see what they
    will need to look like to make sure we have the right authorization.

    ```
    cat policies/dba-operator-policy.hcl
    cat policies/products-api-policy.hcl
    ```

    Once you feel comfortable you understand the policies, write them to Vault.

    ```
    vault policy write dba-operator policies/dba-operator-policy.hcl
    vault policy write products-api policies/products-api-policy.hcl
    ```

    ---

    Now that the policies are in place for your users and applications, you
    should enable the [Userpass auth method](https://www.vaultproject.io/docs/auth/userpass.html)
    and create some users for that auth method that leverage the policies
    you just created.

    ```
    vault auth enable userpass
    ```

    Create a user for Dan on the DBA team - call him `dba-dan`, and make sure that he gets
    the `dba-operator` policy.

    ```
    vault write auth/userpass/users/dba-dan password=dba-dan policies=dba-operator
    ```

    Now that the user is created and configured with the right policy, you should log in
    with the `dba-dan` user and confirm the policies are correctly applied. Before you do
    that, you'll have to unset the `VAULT_TOKEN` environment variable, otherwise it will
    take precedence over the `login` operation you are about to perform.

    ```
    unset VAULT_TOKEN
    vault login -method=userpass username=dba-dan password=dba-dan
    ```

    Note the policy after logging in. Since you have logged in with the DBA user,
    you should be able to read the secret from the `kv/db/*` path, but not from any
    other path.

    ```
    vault read kv/db/postgres/product-db-creds
    vault read kv/not-db/
    ```

    If you can read the credentials but get denied on the `not-db` path, you have
    successfully set up the DBA Operator ACLs.
  notes:
  - type: text
    contents: |-
      Vault centrally secures, stores, and controls access to secrets across
      distributed infrastructure and applications, so it is critical to control
      permissions before any user or machine can gain access.
  - type: text
    contents: |-
      Vault uses policies to govern the the behavior of clients and instrument
      Role-Based Access Control (RBAC) by specifying access prvileges (_authorization_).
      Vault supports both [ACL policies](https://www.vaultproject.io/docs/concepts/policies.html)
      and [Sentinel policies](https://www.vaultproject.io/docs/enterprise/sentinel/index.html).

      This challenge focuses on ACL policies.
  - type: text
    contents: |-
      When you first initialize Vault, the root policy gets created by default. The
      [root policy](https://www.vaultproject.io/docs/concepts/policies/#root-policy)
      is a special policy that gives superuser access to everything in Vault. This
      allows the superuser to set up the initial policies, auth methods, etc.

      This is the policy you have been using up until now.
  - type: text
    contents: |-
      Since Vault enforces the principle of "least-privileged" you should scope
      the access to be as limited as possible.

      As you have already seen - everything in Vault is path based.

      Admins write policies to grant or forbid access to certain paths and operations
      in Vault. Vault operates on a *secure by default standard*, and as such, an empty
      policy grants no permissions in the system.
  - type: text
    contents: |-
      There are two roles at HashiCups that will need access to these secrets.
      The DBA team (`dba-operator`) will need to be able to perform all CRUD operations
      on for the Postgres creds path, and the Products API (`products-api`) only needs
      to read the secrets at that path.
  tabs:
  - title: Terminal
    type: terminal
    hostname: workstation
  - title: Vault UI
    type: service
    hostname: workstation
    path: /ui/
    port: 30082
  - title: Consul UI
    type: service
    hostname: workstation
    path: /ui/
    port: 30085
  - title: K8s UI
    type: service
    hostname: workstation
    port: 30443
  - title: HashiCups Store
    type: service
    hostname: workstation
    path: /
    port: 30090
  difficulty: basic
  timelimit: 300
- slug: static-to-dynamic-database-secrets
  id: atiz2lovvrka
  type: challenge
  title: Static to Dynamic Database Secrets
  teaser: No more shared passwords - set up Vault to generate dynamic secrets for
    the Products database.
  assignment: |-
    In order to generate dynamic secrets for Postgres, the first thing you'll
    need to enable is the `database` secrets engine.

    ```
    vault secrets enable database
    ```

    Once it's enabled, we need to configure it to communicate with the Postgres
    database. We'll use the credentials that we put in the `kv` engine earlier
    in the next step.

    ```
    vault read kv/db/postgres/product-db-creds
    ```

    With the credentials fresh in mind, you must configure the `database`
    secrets engine to communicate with your Postgres server. You'll need to
    get the Cluster IP for the Postgres database, and you should also set the
    PG_USER and POSTGRESS_PASS variables for easy of use and clarity..

    # TODO: Do this with Connect

    ```
    export PG_HOST=$(kubectl get svc -l app=postgres -o=json | jq -r '.items[0].spec.clusterIP')
    export PG_USER=postgres
    export PG_PASS=password
    ```

    ```
    vault write database/config/hashicups-pgsql \
        plugin_name=postgresql-database-plugin \
        allowed_roles="products-api" \
        connection_url="postgresql://{{username}}:{{password}}@$PG_HOST:5432/?sslmode=disable" \
        username=$PG_USER \
        password=$PG_PASS
    ```

    Next, you'll have to configure a role in the `database` secrets engine and associate
    it with a `CREATE ROLE` statement in Postgres. Here you can also configure things like
    the `default_ttl` or `max_ttl`, which refers to the duration of the lease on the
    secrets before they expire and are automatically revoked.

    ```
    vault write database/roles/products-api \
        db_name=hashicups-pgsql \
        creation_statements="CREATE ROLE \"{{name}}\" WITH LOGIN PASSWORD '{{password}}' VALID UNTIL '{{expiration}}' SUPERUSER; \
        GRANT SELECT ON ALL TABLES IN SCHEMA public TO \"{{name}}\";" \
        default_ttl="30m" \
        max_ttl="1h"
    ```

    You are now ready to generate dynamic Postgres credentials.

    ```
    vault read database/creds/products-api
    ```

    Confirm that you can connect to Postgres with these credentials by plugging
    the response values into the below command. Enter the generated password
    when prompted.

    ```
    psql -U YOUR_GENERATED_USERNAME -h $PG_HOST
    ```

    If you can successfully log in,  then you have successfully configured Vault
    for dynamic database credentials and are ready to move on.

    The last thing you want to do is rotate the root credential that you
    configured the database secret engine with, since you don't want anyone
    to be able to use that set of credentials again.

    ```
    vault write -force database/rotate-root/hashicups-pgsql
    ```

    Confirm that you can no longer login with the credentials as before.

    ```
    psql -U postgres -h $PG_HOST
    ```

    Now, you can delete the old path, since we no longer need it.

    ```
    vault kv delete kv/db/postgres/product-db-creds
    ```

    You have successfully configured Vault for dynamic secrets, and eliminated another
    potential security issue by deleting the old credentials and rotating them in Vault.

    Restart the Products API deployment again.

    ```
    kubectl rollout restart deployment products-api-deployment
    ```

    You should notice that the app is broken again. That's because the Products API deployment
    is looking at the old path for it's secrets. Next, you'll learn how to update a
    Kubernetes deployment to leverage the Vault Injector to deliver the secrets to the app.
  notes:
  - type: text
    contents: |-
      Now, you already moved the database credentials for the Products API,
      but it would be even better if you didn't have to use the same credentials,
      and could generate them on the fly.
  - type: text
    contents: |-
      Unlike the KV secrets engine where you had to put data into the store
      yourself, dynamic secrets are generated when they are accessed. Dynamic
      secrets do not exist until they are read, so there is no risk of someone
      stealing them or another client using the same secrets.
  - type: text
    contents: |-
      With every dynamic secret, Vault creates a _lease_: metadata containing
      information such as TTL, renewability, and more. Once the lease is
      expired, Vault can automatically revoke the data, and the consumer of
      the secret can no longer be certain that it is valid.

      Because Vault also has built-in revocation mechanisms, dynamic secrets
      can be revoked immediately after use, minimizing the amount of time the
      secret existed.
  - type: text
    contents: |-
      The `database` secrets engine generates database credentials dynamically
      based on configured roles. With each request, a unique username and
      password pair are generated and returned. While it can manage static roles
      and password rotation, that is not the focus of this challenge.

      The focus is on dynamic Postgres credential generation.
  tabs:
  - title: Terminal
    type: terminal
    hostname: workstation
  - title: Vault UI
    type: service
    hostname: workstation
    path: /ui/
    port: 30082
  - title: Consul UI
    type: service
    hostname: workstation
    path: /ui/
    port: 30085
  - title: K8s UI
    type: service
    hostname: workstation
    port: 30443
  - title: HashiCups Store
    type: service
    hostname: workstation
    path: /
    port: 30090
  difficulty: basic
  timelimit: 300
- slug: vault-agent-with-kubernetes
  id: mn20qfq1soij
  type: challenge
  title: Vault Agent with Kubernetes
  teaser: Modify a Kubernetes deployment file to leverage the Vault agent and inject
    secrets.
  assignment: |-
    The Products API deployment that you have been manipulating over the course
    of this track is located at `/root/product-api.yml`. Take a look inside.

    ```
    less /root/product-api.yml
    ```

    Look around for the string `agent-inject`. You'll notice a reference to a path
    to read from Vault, and template file that will be written to the host
    Vault is deployed on.

    You need to update the path to reflect the one you created in the last
    challenge, `database/creds/products-api`.

    You can do that manually, or you can use this quick one-liner below, once
    understand what you're doing with this command.

    ```
    sed -i 's/kv\/db\/postgres\/product-db-creds/database\/creds\/products-api/g' /root/products-api.yml
    ```

    Update the deployment in Kubernetes.

    ```
    kubectl apply -f products-api.yml
    ```

    Again, restart the deployment.

    ```
    kubectl rollout restart deployment products-api-deployment
    ```

    When you open up the HashiCups UI, you'll notice that it's still broken.
    There is still one last thing that you need to do to get the app fixed and
    fully leveraging dynamic secrets.

    ---

    Remembering what you learned about ACLs earlier in this track, modify
    `/root/policies/products-api-policy.hcl` and update the `products-api`
    policy in Vault to reflect the new path it should have access to read from.
    Open up `/root/policies/products-api.hcl` and make it reflect the below
    policy.

    ```
    path "database/creds/products-api" {
      capabilities = ["read"]
    }
    ```

    Once again, there is a one-liner you can use to achieve this.

    ```
    sed -i 's/kv\/db\/postgres\/product-db-creds/database\/creds\/products-api/g' /root/policies/products-api-policy.hcl
    ```

    You'll then need to upload your changes to Vault.

    ```
    vault policy write products-api policies/products-api-policy.hcl
    ```

    Restart the deployment one last time.

    ```
    kubectl rollout restart deployment products-api-deployment
    ```

    You should now be able to refresh the HashiCups UI and see the products.
    You are now using dynamic credentials, and the root credentials are no
    longer known by anyone on your team.
  notes:
  - type: text
    contents: |-
      HashiCorp provides a tool called `vault-k8s` which leverages the Kubernetes
      Mutating Admission Webhook to intercept and augment specifically annotated
      pod configuration for secrets injection using Init and Sidecar containers.

      Applications need only concern themselves with finding a secret at a filesystem
      path, rather than managing tokens, connecting to an external API, or other
      mechanisms for direct interaction with Vault.
  - type: text
    contents: |-
      For this challenge, you don't have to worry about installing the sidecar
      injector. Instead, you will have to modify an existing Kubernetes deployment
      spec file to read from the path that you just created in the previous challenge.
  tabs:
  - title: Terminal
    type: terminal
    hostname: workstation
  - title: Vault UI
    type: service
    hostname: workstation
    path: /ui/
    port: 30082
  - title: Consul UI
    type: service
    hostname: workstation
    path: /ui/
    port: 30085
  - title: K8s UI
    type: service
    hostname: workstation
    port: 30443
  - title: HashiCups Store
    type: service
    hostname: workstation
    path: /
    port: 30090
  difficulty: basic
  timelimit: 300
checksum: "14459169618522881512"
